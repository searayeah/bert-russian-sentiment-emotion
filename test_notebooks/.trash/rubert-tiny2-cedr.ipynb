{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {},
 "cells": [
  {
   "metadata": {},
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import wandb\n",
    "from datasets import load_dataset\n",
    "from huggingface_hub import notebook_login\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "from transformers import AutoTokenizer, BertForSequenceClassification, DataCollatorWithPadding"
   ],
   "cell_type": "code",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "source": [
    "full_config = {\n",
    "    \"project\": \"VKR\",\n",
    "    \"config\": {\n",
    "        \"dataset\": \"cedr\",\n",
    "        \"num_labels\": 6,\n",
    "        \"labels\": {\n",
    "            0: \"no emotion\",\n",
    "            1: \"joy\",\n",
    "            2: \"sadness\",\n",
    "            3: \"surprise\",\n",
    "            4: \"fear\",\n",
    "            5: \"anger\",\n",
    "        },\n",
    "        \"model\": \"cointegrated/rubert-tiny2\",\n",
    "        \"tokenizer\": \"cointegrated/rubert-tiny2\",\n",
    "        \"problem_type\": \"multi_label_classification\",\n",
    "        \"batch_size\": 64,\n",
    "        \"epochs\": 42,\n",
    "        \"lr\": 1e-5,\n",
    "    },\n",
    "    \"name\": \"rubert-tiny2-cedr\",\n",
    "}\n",
    "config = full_config[\"config\"]"
   ],
   "cell_type": "code",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "source": [
    "def binarize_labels(labels, num_labels):\n",
    "    return [int(len(labels) == 0)] + [int(i in labels) for i in range(num_labels)]\n",
    "\n",
    "\n",
    "def label2id(class_labels):\n",
    "    label2id = {label: i for i, label in enumerate(class_labels)}\n",
    "    id2label = {i: label for label, i in label2id.items()}\n",
    "    return label2id, id2label"
   ],
   "cell_type": "code",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "source": [
    "def calculate_aucs(y_true, y_pred, num_labels):\n",
    "    return [roc_auc_score(y_true[:, i], y_pred[:, i]) for i in range(num_labels)]\n",
    "\n",
    "\n",
    "def calculate_f1_score(y_true, y_pred, average, num_labels):\n",
    "    return [f1_score(y_true[:, i], y_pred[:, i] > 0.5, average=average) for i in range(num_labels)]\n",
    "\n",
    "\n",
    "def calculate_metrics(y_true, y_pred, num_labels):\n",
    "    auc_rocs = calculate_aucs(y_true, y_pred, num_labels)\n",
    "\n",
    "    f1_scores_micro = calculate_f1_score(y_true, y_pred, \"micro\", num_labels)\n",
    "\n",
    "    f1_scores_macro = calculate_f1_score(y_true, y_pred, \"macro\", num_labels)\n",
    "\n",
    "    df = pd.DataFrame(\n",
    "        [auc_rocs, f1_scores_micro, f1_scores_macro],\n",
    "        columns=config[\"labels\"].values(),\n",
    "        index=[\"AUC ROC\", \"F1 micro\", \"F1 macro\"],\n",
    "    )\n",
    "    df[\"mean\"] = df.mean(axis=1)\n",
    "    df[\"mean(emotions)\"] = df.drop(\"no emotion\", axis=1).mean(axis=1)\n",
    "    return df"
   ],
   "cell_type": "code",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "source": [
    "def predict(model, dataloader):\n",
    "    with torch.no_grad():\n",
    "        y_true = []\n",
    "        y_pred = []\n",
    "        for batch in dataloader:\n",
    "            batch = batch.to(model.device)\n",
    "            output = model(**batch)\n",
    "            y_true.append(batch.labels)\n",
    "            y_pred.append(torch.softmax(output.logits, -1))\n",
    "    return torch.cat(y_true).cpu().numpy(), torch.cat(y_pred).cpu().numpy()"
   ],
   "cell_type": "code",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "source": [
    "def train(model, train_dataloader, optimizer, epochs, test_dataloader):\n",
    "    tq = tqdm(range(epochs))\n",
    "\n",
    "    for epoch in tq:\n",
    "        model.train()\n",
    "        for i, batch in enumerate(train_dataloader):\n",
    "            optimizer.zero_grad()\n",
    "            print(batch.keys())\n",
    "            print(type(batch))\n",
    "            batch = batch.to(model.device)\n",
    "            output = model(**batch)\n",
    "            loss = output.loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # if epoch % 5 == 0:\n",
    "        model.eval()\n",
    "\n",
    "        y_true, y_pred = predict(model, train_dataloader)\n",
    "        train_auc = np.mean(calculate_aucs(y_true, y_pred, config[\"num_labels\"]))\n",
    "\n",
    "        y_true, y_pred = predict(model, test_dataloader)\n",
    "        test_auc = np.mean(calculate_aucs(y_true, y_pred, config[\"num_labels\"]))\n",
    "\n",
    "        tq.set_description(f\"loss: {loss.item():4.4f}, AUC: {test_auc:4.4f}\")\n",
    "        wandb.log({\"train_auc\": train_auc, \"test_auc\": test_auc, \"train_loss\": loss.item()})"
   ],
   "cell_type": "code",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "source": [
    "dataset = load_dataset(config[\"dataset\"])"
   ],
   "cell_type": "code",
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Using the latest cached version of the module from /home/seara/.cache/huggingface/modules/datasets_modules/datasets/cedr/117570489cbabbdf8de619bd31918a1cd680a7f286b89d04af340d0691dc2d66 (last modified on Tue Feb 14 12:59:29 2023) since it couldn't be found locally at cedr., or remotely on the Hugging Face Hub.\n",
      "No config specified, defaulting to: cedr/main\n",
      "Found cached dataset cedr (/home/seara/.cache/huggingface/datasets/cedr/main/0.1.1/117570489cbabbdf8de619bd31918a1cd680a7f286b89d04af340d0691dc2d66)\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44155d1b64c74650837048badf3fc111",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(config[\"tokenizer\"])"
   ],
   "cell_type": "code",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "source": [
    "config[\"label2id\"], config[\"id2label\"] = label2id(config[\"labels\"].values())\n",
    "processed_dataset = dataset.map(lambda x: tokenizer(x[\"text\"], truncation=True), batched=True).map(\n",
    "    lambda x: {\"label\": [float(y) for y in binarize_labels(x[\"labels\"], config[\"num_labels\"] - 1)]},\n",
    "    batched=False,\n",
    "    remove_columns=[\"text\", \"labels\", \"source\"],\n",
    ")"
   ],
   "cell_type": "code",
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Loading cached processed dataset at /home/seara/.cache/huggingface/datasets/cedr/main/0.1.1/117570489cbabbdf8de619bd31918a1cd680a7f286b89d04af340d0691dc2d66/cache-cf7aa35d4433e92a.arrow\n",
      "Loading cached processed dataset at /home/seara/.cache/huggingface/datasets/cedr/main/0.1.1/117570489cbabbdf8de619bd31918a1cd680a7f286b89d04af340d0691dc2d66/cache-c0f8df935201b049.arrow\n",
      "Loading cached processed dataset at /home/seara/.cache/huggingface/datasets/cedr/main/0.1.1/117570489cbabbdf8de619bd31918a1cd680a7f286b89d04af340d0691dc2d66/cache-6f9f796a9e6674ba.arrow\n",
      "Loading cached processed dataset at /home/seara/.cache/huggingface/datasets/cedr/main/0.1.1/117570489cbabbdf8de619bd31918a1cd680a7f286b89d04af340d0691dc2d66/cache-ecd0dfddc7f3b5ff.arrow\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    config[\"model\"],\n",
    "    num_labels=config[\"num_labels\"],\n",
    "    problem_type=config[\"problem_type\"],\n",
    "    label2id=config[\"label2id\"],\n",
    "    id2label=config[\"id2label\"],\n",
    ")"
   ],
   "cell_type": "code",
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of the model checkpoint at cointegrated/rubert-tiny2 were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at cointegrated/rubert-tiny2 and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer)\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    processed_dataset[\"train\"],\n",
    "    batch_size=config[\"batch_size\"],\n",
    "    drop_last=False,\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    "    collate_fn=data_collator,\n",
    ")\n",
    "test_dataloader = DataLoader(\n",
    "    processed_dataset[\"test\"],\n",
    "    batch_size=config[\"batch_size\"],\n",
    "    drop_last=False,\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    "    collate_fn=data_collator,\n",
    ")"
   ],
   "cell_type": "code",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "source": [
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=config[\"lr\"])"
   ],
   "cell_type": "code",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "source": [
    "os.environ[\"WANDB_NOTEBOOK_NAME\"] = \"/home/seara/Desktop/Github/vkr/new_era/rubert-tiny2-cedr.ipynb\"\n",
    "wandb.login()\n",
    "wandb.init(**full_config)"
   ],
   "cell_type": "code",
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find /home/seara/Desktop/Github/vkr/new_era/rubert-tiny2-cedr.ipynb.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mseara\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "wandb version 0.14.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/seara/Desktop/Github/vkr/cedr/notebooks/wandb/run-20230413_125146-25k678ux</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/seara/VKR/runs/25k678ux\" target=\"_blank\">rubert-tiny2-cedr</a></strong> to <a href=\"https://wandb.ai/seara/VKR\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/seara/VKR/runs/25k678ux?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7fd2020077c0>"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "source": [
    "model.cuda()\n",
    "train(model, train_dataloader, optimizer, config[\"epochs\"], test_dataloader)"
   ],
   "cell_type": "code",
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "719f1ade6cfd4ef2904e26b12e9df4b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "source": [
    "# notebook_login()"
   ],
   "cell_type": "code",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "source": [
    "calculate_metrics(*predict(model, test_dataloader), config[\"num_labels\"]).round(4)"
   ],
   "cell_type": "code",
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>no emotion</th>\n",
       "      <th>joy</th>\n",
       "      <th>sadness</th>\n",
       "      <th>surprise</th>\n",
       "      <th>fear</th>\n",
       "      <th>anger</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean(emotions)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AUC ROC</th>\n",
       "      <td>0.9239</td>\n",
       "      <td>0.9550</td>\n",
       "      <td>0.9537</td>\n",
       "      <td>0.9045</td>\n",
       "      <td>0.9016</td>\n",
       "      <td>0.7682</td>\n",
       "      <td>0.9011</td>\n",
       "      <td>0.8973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 micro</th>\n",
       "      <td>0.8608</td>\n",
       "      <td>0.9400</td>\n",
       "      <td>0.9336</td>\n",
       "      <td>0.9485</td>\n",
       "      <td>0.9559</td>\n",
       "      <td>0.9192</td>\n",
       "      <td>0.9263</td>\n",
       "      <td>0.9372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 macro</th>\n",
       "      <td>0.8527</td>\n",
       "      <td>0.9005</td>\n",
       "      <td>0.8975</td>\n",
       "      <td>0.8402</td>\n",
       "      <td>0.8350</td>\n",
       "      <td>0.6768</td>\n",
       "      <td>0.8338</td>\n",
       "      <td>0.8306</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          no emotion     joy  sadness  surprise    fear   anger    mean  \\\n",
       "AUC ROC       0.9239  0.9550   0.9537    0.9045  0.9016  0.7682  0.9011   \n",
       "F1 micro      0.8608  0.9400   0.9336    0.9485  0.9559  0.9192  0.9263   \n",
       "F1 macro      0.8527  0.9005   0.8975    0.8402  0.8350  0.6768  0.8338   \n",
       "\n",
       "          mean(emotions)  \n",
       "AUC ROC           0.8973  \n",
       "F1 micro          0.9372  \n",
       "F1 macro          0.8306  "
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "source": [
    "model.push_to_hub(full_config[\"name\"])\n",
    "tokenizer.push_to_hub(full_config[\"name\"])"
   ],
   "cell_type": "code",
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/seara/rubert-tiny2-cedr/commit/241abd5e1685e91cee1f1843d99cf16c0a8e285f', commit_message='Upload tokenizer', commit_description='', oid='241abd5e1685e91cee1f1843d99cf16c0a8e285f', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "source": [
    "wandb.finish()"
   ],
   "cell_type": "code",
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>test_auc</td><td>▁▂▂▄▅▅▆▇▇▇▇▇▇▇██████████████████████████</td></tr><tr><td>train_auc</td><td>▁▂▂▃▄▄▅▆▆▆▆▇▇▇▇▇▇▇▇█████████████████████</td></tr><tr><td>train_loss</td><td>█▇▆▆▅▄▅▅▅▄▄▄▃▃▃▂▃▃▃▃▂▂▂▂▂▂▃▂▁▂▂▁▁▂▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>test_auc</td><td>0.90113</td></tr><tr><td>train_auc</td><td>0.99792</td></tr><tr><td>train_loss</td><td>0.02599</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">rubert-tiny2-cedr</strong>: <a href=\"https://wandb.ai/seara/VKR/runs/2k3va9u2\" target=\"_blank\">https://wandb.ai/seara/VKR/runs/2k3va9u2</a><br/>Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230408_165201-2k3va9u2/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {}
    }
   ],
   "execution_count": null
  }
 ]
}
