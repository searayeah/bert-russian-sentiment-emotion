{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertForSequenceClassification\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at DeepPavlov/rubert-base-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at DeepPavlov/rubert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of the model checkpoint at cointegrated/rubert-tiny2 were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at cointegrated/rubert-tiny2 and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\"DeepPavlov/rubert-base-cased\")\n",
    "model = BertForSequenceClassification.from_pretrained(\"cointegrated/rubert-tiny2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29194394"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "api = wandb.Api()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep = api.sweep(\"seara/VKR-rubert-tiny2-cedr/0cvqljnl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toasty-sweep-48 0.1968657632668813 0.9217179852188511\n",
      "crimson-sweep-47 0.2027400975426038 0.9223015447894453\n",
      "efficient-sweep-46 0.2009123275677363 0.9162158947530091\n",
      "stellar-sweep-45 0.19525499393542609 0.9068813829271098\n",
      "comfy-sweep-44 0.21025601923465728 0.8940428073010404\n",
      "eager-sweep-43 0.20958553900321325 0.905679432843221\n",
      "smooth-sweep-42 0.20516089896361034 0.8993677156132333\n",
      "fragrant-sweep-41 0.20244243641694387 0.9037201074481637\n",
      "desert-sweep-40 0.2010574907064438 0.916099664633124\n",
      "avid-sweep-39 0.2012837712963422 0.9058026080352067\n",
      "solar-sweep-38 0.20006040235360464 0.907719078532277\n",
      "polished-sweep-37 0.20466861873865128 0.9055644675450147\n",
      "mild-sweep-36 0.2012048934896787 0.9076219773480316\n",
      "likely-sweep-35 0.20198760976394017 0.9117887934831339\n",
      "avid-sweep-34 0.20215335339307786 0.90641661751989\n",
      "swept-sweep-33 0.19881214102109274 0.9023936056128736\n",
      "woven-sweep-32 0.20109235594669977 0.9137259972482495\n",
      "mild-sweep-31 0.19878647948304812 0.9097275560760244\n",
      "tough-sweep-30 0.1968444675207138 0.9111133845177942\n",
      "visionary-sweep-29 0.20157257368167242 0.9128269500723477\n",
      "vague-sweep-28 0.20707487364610036 0.9034778706248043\n",
      "wandering-sweep-27 0.19974947348237038 0.9132736835338301\n",
      "absurd-sweep-26 0.19686402181784313 0.9080393160011025\n",
      "silvery-sweep-25 0.20444305886824926 0.904678291730625\n",
      "denim-sweep-24 0.1872231998180939 0.9248422685748686\n",
      "trim-sweep-23 0.19111933900138078 0.9198669830786219\n",
      "fresh-sweep-22 0.19065382836733835 0.9196576054227069\n",
      "bright-sweep-21 0.1887434589660774 0.9196772841047484\n",
      "atomic-sweep-20 0.19406048397896652 0.9185343682591518\n",
      "sunny-sweep-19 0.19786945844100692 0.9062874519768803\n",
      "ethereal-sweep-18 0.19956391809855478 0.9083948990100573\n",
      "avid-sweep-17 0.19370747812218586 0.9154290999782213\n",
      "fine-sweep-16 0.1947534543983007 0.9194479222801214\n",
      "classic-sweep-15 0.19271373142630366 0.9147488869265096\n",
      "eager-sweep-14 0.196067638568959 0.9182566246848913\n",
      "visionary-sweep-13 0.1899850070476532 0.9202425860138295\n",
      "olive-sweep-12 0.1903524483411999 0.915862928006634\n",
      "desert-sweep-11 0.19512158505997415 0.9126138302964161\n",
      "usual-sweep-10 0.194169492792275 0.912647412590815\n",
      "fresh-sweep-9 0.1944666900119539 0.9243106132782186\n",
      "trim-sweep-8 0.19619285795143096 0.9188391182291009\n",
      "rare-sweep-7 0.19332781219381398 0.9048200577895141\n",
      "resilient-sweep-6 0.19265060846583318 0.9215060675416379\n",
      "vivid-sweep-5 0.19058722383895163 0.922369350165603\n",
      "snowy-sweep-4 0.20015879467887393 0.9089251699054318\n",
      "curious-sweep-3 0.1984028715198323 0.9130991850679727\n",
      "woven-sweep-2 0.19864453173289864 0.906637009856447\n",
      "solar-sweep-1 0.2018699157288519 0.9009373219274659\n"
     ]
    }
   ],
   "source": [
    "for run in sweep.runs:\n",
    "    test_losses = run.history()[\"test_loss\"].to_list()\n",
    "    test_aucs = run.history()[\"test_auc\"].to_list()\n",
    "\n",
    "    minimum_loss = np.min(test_losses)\n",
    "    minimum_loss_index= np.argmin(test_losses)\n",
    "    auc_at_minimum_loss = test_aucs[minimum_loss_index]\n",
    "\n",
    "    print(run.name, minimum_loss, auc_at_minimum_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9217179852188511"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc_at_minimum_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minimum_loss_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_step</th>\n",
       "      <th>train_auc</th>\n",
       "      <th>test_auc</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>_runtime</th>\n",
       "      <th>test_loss</th>\n",
       "      <th>_timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.715472</td>\n",
       "      <td>0.853141</td>\n",
       "      <td>0.367497</td>\n",
       "      <td>8.815503</td>\n",
       "      <td>0.263960</td>\n",
       "      <td>1.681483e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.893937</td>\n",
       "      <td>0.911451</td>\n",
       "      <td>0.213870</td>\n",
       "      <td>13.544583</td>\n",
       "      <td>0.200700</td>\n",
       "      <td>1.681483e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.953213</td>\n",
       "      <td>0.921718</td>\n",
       "      <td>0.143491</td>\n",
       "      <td>18.312662</td>\n",
       "      <td>0.196866</td>\n",
       "      <td>1.681483e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.979822</td>\n",
       "      <td>0.920910</td>\n",
       "      <td>0.093992</td>\n",
       "      <td>23.011497</td>\n",
       "      <td>0.206914</td>\n",
       "      <td>1.681483e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.992209</td>\n",
       "      <td>0.911719</td>\n",
       "      <td>0.058866</td>\n",
       "      <td>27.851357</td>\n",
       "      <td>0.233045</td>\n",
       "      <td>1.681483e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.996095</td>\n",
       "      <td>0.897832</td>\n",
       "      <td>0.036919</td>\n",
       "      <td>32.608980</td>\n",
       "      <td>0.251416</td>\n",
       "      <td>1.681483e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.997567</td>\n",
       "      <td>0.896595</td>\n",
       "      <td>0.025289</td>\n",
       "      <td>37.335374</td>\n",
       "      <td>0.278378</td>\n",
       "      <td>1.681483e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.998511</td>\n",
       "      <td>0.900292</td>\n",
       "      <td>0.019722</td>\n",
       "      <td>41.971857</td>\n",
       "      <td>0.326912</td>\n",
       "      <td>1.681483e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.998940</td>\n",
       "      <td>0.901790</td>\n",
       "      <td>0.017038</td>\n",
       "      <td>46.736348</td>\n",
       "      <td>0.302155</td>\n",
       "      <td>1.681483e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.999214</td>\n",
       "      <td>0.906492</td>\n",
       "      <td>0.015895</td>\n",
       "      <td>51.553525</td>\n",
       "      <td>0.326464</td>\n",
       "      <td>1.681483e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>0.999464</td>\n",
       "      <td>0.877842</td>\n",
       "      <td>0.010989</td>\n",
       "      <td>56.301496</td>\n",
       "      <td>0.317736</td>\n",
       "      <td>1.681483e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>0.999650</td>\n",
       "      <td>0.897918</td>\n",
       "      <td>0.009647</td>\n",
       "      <td>61.137530</td>\n",
       "      <td>0.325987</td>\n",
       "      <td>1.681483e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>0.999850</td>\n",
       "      <td>0.882527</td>\n",
       "      <td>0.007254</td>\n",
       "      <td>65.974050</td>\n",
       "      <td>0.347048</td>\n",
       "      <td>1.681483e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>0.999892</td>\n",
       "      <td>0.901897</td>\n",
       "      <td>0.006072</td>\n",
       "      <td>70.683728</td>\n",
       "      <td>0.347728</td>\n",
       "      <td>1.681483e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>0.999952</td>\n",
       "      <td>0.901448</td>\n",
       "      <td>0.005181</td>\n",
       "      <td>75.521378</td>\n",
       "      <td>0.342306</td>\n",
       "      <td>1.681483e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>0.999958</td>\n",
       "      <td>0.892168</td>\n",
       "      <td>0.004440</td>\n",
       "      <td>80.285953</td>\n",
       "      <td>0.364439</td>\n",
       "      <td>1.681483e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>0.999986</td>\n",
       "      <td>0.907330</td>\n",
       "      <td>0.003935</td>\n",
       "      <td>85.081898</td>\n",
       "      <td>0.350023</td>\n",
       "      <td>1.681483e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>0.999680</td>\n",
       "      <td>0.867442</td>\n",
       "      <td>0.007601</td>\n",
       "      <td>89.759225</td>\n",
       "      <td>0.376319</td>\n",
       "      <td>1.681483e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>0.999895</td>\n",
       "      <td>0.892663</td>\n",
       "      <td>0.006573</td>\n",
       "      <td>94.547860</td>\n",
       "      <td>0.386435</td>\n",
       "      <td>1.681483e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>0.999941</td>\n",
       "      <td>0.892825</td>\n",
       "      <td>0.004764</td>\n",
       "      <td>99.588524</td>\n",
       "      <td>0.363204</td>\n",
       "      <td>1.681483e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>0.999973</td>\n",
       "      <td>0.877065</td>\n",
       "      <td>0.003111</td>\n",
       "      <td>104.339241</td>\n",
       "      <td>0.387416</td>\n",
       "      <td>1.681483e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>0.999956</td>\n",
       "      <td>0.890016</td>\n",
       "      <td>0.002698</td>\n",
       "      <td>109.199309</td>\n",
       "      <td>0.388771</td>\n",
       "      <td>1.681483e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>0.999991</td>\n",
       "      <td>0.880569</td>\n",
       "      <td>0.001960</td>\n",
       "      <td>113.993200</td>\n",
       "      <td>0.399624</td>\n",
       "      <td>1.681483e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>0.889724</td>\n",
       "      <td>0.001894</td>\n",
       "      <td>118.800749</td>\n",
       "      <td>0.387893</td>\n",
       "      <td>1.681483e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>0.999993</td>\n",
       "      <td>0.884799</td>\n",
       "      <td>0.001732</td>\n",
       "      <td>123.579397</td>\n",
       "      <td>0.408740</td>\n",
       "      <td>1.681483e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>0.887512</td>\n",
       "      <td>0.001364</td>\n",
       "      <td>128.435617</td>\n",
       "      <td>0.407040</td>\n",
       "      <td>1.681483e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>0.999992</td>\n",
       "      <td>0.893949</td>\n",
       "      <td>0.001430</td>\n",
       "      <td>133.266914</td>\n",
       "      <td>0.408066</td>\n",
       "      <td>1.681483e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>0.880425</td>\n",
       "      <td>0.001242</td>\n",
       "      <td>138.050059</td>\n",
       "      <td>0.430083</td>\n",
       "      <td>1.681484e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>0.999995</td>\n",
       "      <td>0.875095</td>\n",
       "      <td>0.001350</td>\n",
       "      <td>142.887734</td>\n",
       "      <td>0.432195</td>\n",
       "      <td>1.681484e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>0.999973</td>\n",
       "      <td>0.869006</td>\n",
       "      <td>0.003546</td>\n",
       "      <td>147.754433</td>\n",
       "      <td>0.445872</td>\n",
       "      <td>1.681484e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>30</td>\n",
       "      <td>0.999963</td>\n",
       "      <td>0.893695</td>\n",
       "      <td>0.001980</td>\n",
       "      <td>152.592833</td>\n",
       "      <td>0.451404</td>\n",
       "      <td>1.681484e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>31</td>\n",
       "      <td>0.999832</td>\n",
       "      <td>0.868146</td>\n",
       "      <td>0.003203</td>\n",
       "      <td>157.455738</td>\n",
       "      <td>0.476496</td>\n",
       "      <td>1.681484e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>32</td>\n",
       "      <td>0.999820</td>\n",
       "      <td>0.904587</td>\n",
       "      <td>0.004798</td>\n",
       "      <td>162.305322</td>\n",
       "      <td>0.435381</td>\n",
       "      <td>1.681484e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>33</td>\n",
       "      <td>0.999471</td>\n",
       "      <td>0.880987</td>\n",
       "      <td>0.007116</td>\n",
       "      <td>167.177429</td>\n",
       "      <td>0.445663</td>\n",
       "      <td>1.681484e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>34</td>\n",
       "      <td>0.999990</td>\n",
       "      <td>0.889693</td>\n",
       "      <td>0.001602</td>\n",
       "      <td>171.986142</td>\n",
       "      <td>0.424892</td>\n",
       "      <td>1.681484e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>35</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>0.900025</td>\n",
       "      <td>0.001077</td>\n",
       "      <td>176.764729</td>\n",
       "      <td>0.420367</td>\n",
       "      <td>1.681484e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>36</td>\n",
       "      <td>0.999992</td>\n",
       "      <td>0.883074</td>\n",
       "      <td>0.001246</td>\n",
       "      <td>181.517173</td>\n",
       "      <td>0.460081</td>\n",
       "      <td>1.681484e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>37</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>0.880881</td>\n",
       "      <td>0.000810</td>\n",
       "      <td>186.256055</td>\n",
       "      <td>0.462667</td>\n",
       "      <td>1.681484e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>38</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.882740</td>\n",
       "      <td>0.000662</td>\n",
       "      <td>191.099297</td>\n",
       "      <td>0.461682</td>\n",
       "      <td>1.681484e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>39</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.880967</td>\n",
       "      <td>0.000718</td>\n",
       "      <td>195.989282</td>\n",
       "      <td>0.470164</td>\n",
       "      <td>1.681484e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>40</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>0.898703</td>\n",
       "      <td>0.000849</td>\n",
       "      <td>200.836269</td>\n",
       "      <td>0.461007</td>\n",
       "      <td>1.681484e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>41</td>\n",
       "      <td>0.999995</td>\n",
       "      <td>0.878403</td>\n",
       "      <td>0.001217</td>\n",
       "      <td>205.656557</td>\n",
       "      <td>0.482816</td>\n",
       "      <td>1.681484e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>42</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.882002</td>\n",
       "      <td>0.000406</td>\n",
       "      <td>210.456784</td>\n",
       "      <td>0.461511</td>\n",
       "      <td>1.681484e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>43</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.876207</td>\n",
       "      <td>0.000372</td>\n",
       "      <td>215.291442</td>\n",
       "      <td>0.478120</td>\n",
       "      <td>1.681484e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>44</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.879521</td>\n",
       "      <td>0.000307</td>\n",
       "      <td>220.088201</td>\n",
       "      <td>0.475023</td>\n",
       "      <td>1.681484e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>45</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>0.877226</td>\n",
       "      <td>0.000422</td>\n",
       "      <td>224.944166</td>\n",
       "      <td>0.475943</td>\n",
       "      <td>1.681484e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>46</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>0.878442</td>\n",
       "      <td>0.000434</td>\n",
       "      <td>229.696111</td>\n",
       "      <td>0.483185</td>\n",
       "      <td>1.681484e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>47</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.870443</td>\n",
       "      <td>0.000580</td>\n",
       "      <td>234.485728</td>\n",
       "      <td>0.519957</td>\n",
       "      <td>1.681484e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>48</td>\n",
       "      <td>0.999955</td>\n",
       "      <td>0.858166</td>\n",
       "      <td>0.004469</td>\n",
       "      <td>239.327088</td>\n",
       "      <td>0.553933</td>\n",
       "      <td>1.681484e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>49</td>\n",
       "      <td>0.999460</td>\n",
       "      <td>0.899192</td>\n",
       "      <td>0.011203</td>\n",
       "      <td>244.150726</td>\n",
       "      <td>0.451309</td>\n",
       "      <td>1.681484e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    _step  train_auc  test_auc  train_loss    _runtime  test_loss  \\\n",
       "0       0   0.715472  0.853141    0.367497    8.815503   0.263960   \n",
       "1       1   0.893937  0.911451    0.213870   13.544583   0.200700   \n",
       "2       2   0.953213  0.921718    0.143491   18.312662   0.196866   \n",
       "3       3   0.979822  0.920910    0.093992   23.011497   0.206914   \n",
       "4       4   0.992209  0.911719    0.058866   27.851357   0.233045   \n",
       "5       5   0.996095  0.897832    0.036919   32.608980   0.251416   \n",
       "6       6   0.997567  0.896595    0.025289   37.335374   0.278378   \n",
       "7       7   0.998511  0.900292    0.019722   41.971857   0.326912   \n",
       "8       8   0.998940  0.901790    0.017038   46.736348   0.302155   \n",
       "9       9   0.999214  0.906492    0.015895   51.553525   0.326464   \n",
       "10     10   0.999464  0.877842    0.010989   56.301496   0.317736   \n",
       "11     11   0.999650  0.897918    0.009647   61.137530   0.325987   \n",
       "12     12   0.999850  0.882527    0.007254   65.974050   0.347048   \n",
       "13     13   0.999892  0.901897    0.006072   70.683728   0.347728   \n",
       "14     14   0.999952  0.901448    0.005181   75.521378   0.342306   \n",
       "15     15   0.999958  0.892168    0.004440   80.285953   0.364439   \n",
       "16     16   0.999986  0.907330    0.003935   85.081898   0.350023   \n",
       "17     17   0.999680  0.867442    0.007601   89.759225   0.376319   \n",
       "18     18   0.999895  0.892663    0.006573   94.547860   0.386435   \n",
       "19     19   0.999941  0.892825    0.004764   99.588524   0.363204   \n",
       "20     20   0.999973  0.877065    0.003111  104.339241   0.387416   \n",
       "21     21   0.999956  0.890016    0.002698  109.199309   0.388771   \n",
       "22     22   0.999991  0.880569    0.001960  113.993200   0.399624   \n",
       "23     23   0.999997  0.889724    0.001894  118.800749   0.387893   \n",
       "24     24   0.999993  0.884799    0.001732  123.579397   0.408740   \n",
       "25     25   0.999996  0.887512    0.001364  128.435617   0.407040   \n",
       "26     26   0.999992  0.893949    0.001430  133.266914   0.408066   \n",
       "27     27   0.999997  0.880425    0.001242  138.050059   0.430083   \n",
       "28     28   0.999995  0.875095    0.001350  142.887734   0.432195   \n",
       "29     29   0.999973  0.869006    0.003546  147.754433   0.445872   \n",
       "30     30   0.999963  0.893695    0.001980  152.592833   0.451404   \n",
       "31     31   0.999832  0.868146    0.003203  157.455738   0.476496   \n",
       "32     32   0.999820  0.904587    0.004798  162.305322   0.435381   \n",
       "33     33   0.999471  0.880987    0.007116  167.177429   0.445663   \n",
       "34     34   0.999990  0.889693    0.001602  171.986142   0.424892   \n",
       "35     35   0.999996  0.900025    0.001077  176.764729   0.420367   \n",
       "36     36   0.999992  0.883074    0.001246  181.517173   0.460081   \n",
       "37     37   0.999999  0.880881    0.000810  186.256055   0.462667   \n",
       "38     38   0.999998  0.882740    0.000662  191.099297   0.461682   \n",
       "39     39   0.999998  0.880967    0.000718  195.989282   0.470164   \n",
       "40     40   0.999996  0.898703    0.000849  200.836269   0.461007   \n",
       "41     41   0.999995  0.878403    0.001217  205.656557   0.482816   \n",
       "42     42   1.000000  0.882002    0.000406  210.456784   0.461511   \n",
       "43     43   1.000000  0.876207    0.000372  215.291442   0.478120   \n",
       "44     44   1.000000  0.879521    0.000307  220.088201   0.475023   \n",
       "45     45   0.999999  0.877226    0.000422  224.944166   0.475943   \n",
       "46     46   0.999997  0.878442    0.000434  229.696111   0.483185   \n",
       "47     47   0.999998  0.870443    0.000580  234.485728   0.519957   \n",
       "48     48   0.999955  0.858166    0.004469  239.327088   0.553933   \n",
       "49     49   0.999460  0.899192    0.011203  244.150726   0.451309   \n",
       "\n",
       "      _timestamp  \n",
       "0   1.681483e+09  \n",
       "1   1.681483e+09  \n",
       "2   1.681483e+09  \n",
       "3   1.681483e+09  \n",
       "4   1.681483e+09  \n",
       "5   1.681483e+09  \n",
       "6   1.681483e+09  \n",
       "7   1.681483e+09  \n",
       "8   1.681483e+09  \n",
       "9   1.681483e+09  \n",
       "10  1.681483e+09  \n",
       "11  1.681483e+09  \n",
       "12  1.681483e+09  \n",
       "13  1.681483e+09  \n",
       "14  1.681483e+09  \n",
       "15  1.681483e+09  \n",
       "16  1.681483e+09  \n",
       "17  1.681483e+09  \n",
       "18  1.681483e+09  \n",
       "19  1.681483e+09  \n",
       "20  1.681483e+09  \n",
       "21  1.681483e+09  \n",
       "22  1.681483e+09  \n",
       "23  1.681483e+09  \n",
       "24  1.681483e+09  \n",
       "25  1.681483e+09  \n",
       "26  1.681483e+09  \n",
       "27  1.681484e+09  \n",
       "28  1.681484e+09  \n",
       "29  1.681484e+09  \n",
       "30  1.681484e+09  \n",
       "31  1.681484e+09  \n",
       "32  1.681484e+09  \n",
       "33  1.681484e+09  \n",
       "34  1.681484e+09  \n",
       "35  1.681484e+09  \n",
       "36  1.681484e+09  \n",
       "37  1.681484e+09  \n",
       "38  1.681484e+09  \n",
       "39  1.681484e+09  \n",
       "40  1.681484e+09  \n",
       "41  1.681484e+09  \n",
       "42  1.681484e+09  \n",
       "43  1.681484e+09  \n",
       "44  1.681484e+09  \n",
       "45  1.681484e+09  \n",
       "46  1.681484e+09  \n",
       "47  1.681484e+09  \n",
       "48  1.681484e+09  \n",
       "49  1.681484e+09  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sweep.runs[0].history()\n",
    "# sweep.runs[0].name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toasty-sweep-48\n",
      "crimson-sweep-47\n",
      "efficient-sweep-46\n",
      "stellar-sweep-45\n",
      "comfy-sweep-44\n",
      "eager-sweep-43\n",
      "smooth-sweep-42\n",
      "fragrant-sweep-41\n",
      "desert-sweep-40\n",
      "avid-sweep-39\n",
      "solar-sweep-38\n",
      "polished-sweep-37\n",
      "mild-sweep-36\n",
      "likely-sweep-35\n",
      "avid-sweep-34\n",
      "swept-sweep-33\n",
      "woven-sweep-32\n",
      "mild-sweep-31\n",
      "tough-sweep-30\n",
      "visionary-sweep-29\n",
      "vague-sweep-28\n",
      "wandering-sweep-27\n",
      "absurd-sweep-26\n",
      "silvery-sweep-25\n",
      "denim-sweep-24\n",
      "trim-sweep-23\n",
      "fresh-sweep-22\n",
      "bright-sweep-21\n",
      "atomic-sweep-20\n",
      "sunny-sweep-19\n",
      "ethereal-sweep-18\n",
      "avid-sweep-17\n",
      "fine-sweep-16\n",
      "classic-sweep-15\n",
      "eager-sweep-14\n",
      "visionary-sweep-13\n",
      "olive-sweep-12\n",
      "desert-sweep-11\n",
      "usual-sweep-10\n",
      "fresh-sweep-9\n",
      "trim-sweep-8\n",
      "rare-sweep-7\n",
      "resilient-sweep-6\n",
      "vivid-sweep-5\n",
      "snowy-sweep-4\n",
      "curious-sweep-3\n",
      "woven-sweep-2\n",
      "solar-sweep-1\n"
     ]
    }
   ],
   "source": [
    "for run in sweep.runs:\n",
    "    print(run.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_timestamp': 1681483607.063055, 'train_loss': 0.01120283265481703, '_step': 49, '_wandb': {'runtime': 243}, '_runtime': 244.1507260799408, 'test_auc': 0.8991922726492209, 'test_loss': 0.4513089925050736, 'train_auc': 0.9994598962559778}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sweep.runs[0].summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "runs = sorted(sweep.runs,\n",
    "  key=lambda run: run.summary.get(\"val_acc\", 0), reverse=True)\n",
    "val_acc = runs[0].summary.get(\"val_acc\", 0)\n",
    "print(f\"Best run {runs[0].name} with {val_acc}% validation accuracy\")\n",
    "\n",
    "runs[0].file(\"model.h5\").download(replace=True)\n",
    "print(\"Best model saved to model-best.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertForSequenceClassification, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cointegrated/rubert-tiny2 were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at cointegrated/rubert-tiny2 and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\"cointegrated/rubert-tiny2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c12e20f878f24e6891ada7b82f54ff8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/117M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eeeca1a8f78a457cb99d721e40e37a6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 1 LFS files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/seara/searaanothertest/commit/9dc74dd4310ccd1d6135a270a027cedd136e2093', commit_message='Upload BertForSequenceClassification', commit_description='', oid='9dc74dd4310ccd1d6135a270a027cedd136e2093', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.push_to_hub(\"searaanothertest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_branch(repo_id=\"seara/searaanothertest\", branch=\"testbranch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"cointegrated/rubert-tiny2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/seara/searaanothertest/commit/67f2b74dd5dc5549efb194e2fa82b407c3c06b79', commit_message='Upload tokenizer', commit_description='', oid='67f2b74dd5dc5549efb194e2fa82b407c3c06b79', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.push_to_hub(\"searaanothertest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/seara/searaanothertest/commit/d87a37677f7234f6c0e11ac999a384d1559b23f6', commit_message='Upload BertForSequenceClassification', commit_description='', oid='d87a37677f7234f6c0e11ac999a384d1559b23f6', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.push_to_hub(\"searaanothertest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def push_to_hub(model, tokenizer, name, create_branch=False, branch_name=None):\n",
    "    if create_branch:\n",
    "        create_branch(name, branch_name)\n",
    "    model.push_to_hub(name)\n",
    "    tokenizer.push_to_hub(name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "Couldn't find a dataset script at /home/seara/Desktop/Github/vkr/models/go-emotions/go-emotions.py or any data file in the same directory. Couldn't find 'go-emotions' on the Hugging Face Hub either: FileNotFoundError: Dataset 'go-emotions' doesn't exist on the Hub",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m load_dataset(\u001b[39m\"\u001b[39;49m\u001b[39mgo-emotions\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.16/envs/DS/lib/python3.9/site-packages/datasets/load.py:1735\u001b[0m, in \u001b[0;36mload_dataset\u001b[0;34m(path, name, data_dir, data_files, split, cache_dir, features, download_config, download_mode, ignore_verifications, keep_in_memory, save_infos, revision, use_auth_token, task, streaming, num_proc, **config_kwargs)\u001b[0m\n\u001b[1;32m   1732\u001b[0m ignore_verifications \u001b[39m=\u001b[39m ignore_verifications \u001b[39mor\u001b[39;00m save_infos\n\u001b[1;32m   1734\u001b[0m \u001b[39m# Create a dataset builder\u001b[39;00m\n\u001b[0;32m-> 1735\u001b[0m builder_instance \u001b[39m=\u001b[39m load_dataset_builder(\n\u001b[1;32m   1736\u001b[0m     path\u001b[39m=\u001b[39;49mpath,\n\u001b[1;32m   1737\u001b[0m     name\u001b[39m=\u001b[39;49mname,\n\u001b[1;32m   1738\u001b[0m     data_dir\u001b[39m=\u001b[39;49mdata_dir,\n\u001b[1;32m   1739\u001b[0m     data_files\u001b[39m=\u001b[39;49mdata_files,\n\u001b[1;32m   1740\u001b[0m     cache_dir\u001b[39m=\u001b[39;49mcache_dir,\n\u001b[1;32m   1741\u001b[0m     features\u001b[39m=\u001b[39;49mfeatures,\n\u001b[1;32m   1742\u001b[0m     download_config\u001b[39m=\u001b[39;49mdownload_config,\n\u001b[1;32m   1743\u001b[0m     download_mode\u001b[39m=\u001b[39;49mdownload_mode,\n\u001b[1;32m   1744\u001b[0m     revision\u001b[39m=\u001b[39;49mrevision,\n\u001b[1;32m   1745\u001b[0m     use_auth_token\u001b[39m=\u001b[39;49muse_auth_token,\n\u001b[1;32m   1746\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mconfig_kwargs,\n\u001b[1;32m   1747\u001b[0m )\n\u001b[1;32m   1749\u001b[0m \u001b[39m# Return iterable dataset in case of streaming\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[39mif\u001b[39;00m streaming:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.16/envs/DS/lib/python3.9/site-packages/datasets/load.py:1493\u001b[0m, in \u001b[0;36mload_dataset_builder\u001b[0;34m(path, name, data_dir, data_files, cache_dir, features, download_config, download_mode, revision, use_auth_token, **config_kwargs)\u001b[0m\n\u001b[1;32m   1491\u001b[0m     download_config \u001b[39m=\u001b[39m download_config\u001b[39m.\u001b[39mcopy() \u001b[39mif\u001b[39;00m download_config \u001b[39melse\u001b[39;00m DownloadConfig()\n\u001b[1;32m   1492\u001b[0m     download_config\u001b[39m.\u001b[39muse_auth_token \u001b[39m=\u001b[39m use_auth_token\n\u001b[0;32m-> 1493\u001b[0m dataset_module \u001b[39m=\u001b[39m dataset_module_factory(\n\u001b[1;32m   1494\u001b[0m     path,\n\u001b[1;32m   1495\u001b[0m     revision\u001b[39m=\u001b[39;49mrevision,\n\u001b[1;32m   1496\u001b[0m     download_config\u001b[39m=\u001b[39;49mdownload_config,\n\u001b[1;32m   1497\u001b[0m     download_mode\u001b[39m=\u001b[39;49mdownload_mode,\n\u001b[1;32m   1498\u001b[0m     data_dir\u001b[39m=\u001b[39;49mdata_dir,\n\u001b[1;32m   1499\u001b[0m     data_files\u001b[39m=\u001b[39;49mdata_files,\n\u001b[1;32m   1500\u001b[0m )\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Get dataset builder class from the processing script\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m builder_cls \u001b[39m=\u001b[39m import_main_class(dataset_module\u001b[39m.\u001b[39mmodule_path)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.16/envs/DS/lib/python3.9/site-packages/datasets/load.py:1213\u001b[0m, in \u001b[0;36mdataset_module_factory\u001b[0;34m(path, revision, download_config, download_mode, dynamic_modules_path, data_dir, data_files, **download_kwargs)\u001b[0m\n\u001b[1;32m   1211\u001b[0m                 \u001b[39mraise\u001b[39;00m e1 \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m   1212\u001b[0m             \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(e1, \u001b[39mFileNotFoundError\u001b[39;00m):\n\u001b[0;32m-> 1213\u001b[0m                 \u001b[39mraise\u001b[39;00m \u001b[39mFileNotFoundError\u001b[39;00m(\n\u001b[1;32m   1214\u001b[0m                     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCouldn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt find a dataset script at \u001b[39m\u001b[39m{\u001b[39;00mrelative_to_absolute_path(combined_path)\u001b[39m}\u001b[39;00m\u001b[39m or any data file in the same directory. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1215\u001b[0m                     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCouldn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt find \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mpath\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m on the Hugging Face Hub either: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(e1)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m: \u001b[39m\u001b[39m{\u001b[39;00me1\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1216\u001b[0m                 ) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m   1217\u001b[0m             \u001b[39mraise\u001b[39;00m e1 \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m   1218\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: Couldn't find a dataset script at /home/seara/Desktop/Github/vkr/models/go-emotions/go-emotions.py or any data file in the same directory. Couldn't find 'go-emotions' on the Hugging Face Hub either: FileNotFoundError: Dataset 'go-emotions' doesn't exist on the Hub"
     ]
    }
   ],
   "source": [
    "\n",
    "load_dataset(\"go-emotions\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'project_name': 'VKR',\n",
       " 'data': {'name': 'cedr',\n",
       "  'num_labels': 5,\n",
       "  'labels': {1: 'joy', 2: 'sadness', 3: 'surprise', 4: 'fear', 5: 'anger'}}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 5, 'epochs': 4, 'batch_size': [1, 2, 3, 4], 'model': {'dataset': 5, 'optimizer': 2}}\n"
     ]
    }
   ],
   "source": [
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "namedtuple() missing 1 required positional argument: 'field_names'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m a \u001b[39m=\u001b[39m namedtuple(\u001b[39m\"\u001b[39;49m\u001b[39mconfig\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "\u001b[0;31mTypeError\u001b[0m: namedtuple() missing 1 required positional argument: 'field_names'"
     ]
    }
   ],
   "source": [
    "from types import SimpleNamespace"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
