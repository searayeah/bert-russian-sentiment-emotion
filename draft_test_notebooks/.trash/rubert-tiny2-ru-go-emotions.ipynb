{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {},
 "cells": [
  {
   "metadata": {},
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import wandb\n",
    "from datasets import concatenate_datasets, load_dataset\n",
    "from huggingface_hub import notebook_login\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "from transformers import AutoTokenizer, BertForSequenceClassification, DataCollatorWithPadding"
   ],
   "cell_type": "code",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "source": [
    "full_config = {\n",
    "    \"project\": \"VKR\",\n",
    "    \"config\": {\n",
    "        \"dataset\": \"seara/ru_go_emotions\",\n",
    "        \"num_labels\": 28,\n",
    "        \"labels\": {\n",
    "            0: \"admiration\",\n",
    "            1: \"amusement\",\n",
    "            2: \"anger\",\n",
    "            3: \"annoyance\",\n",
    "            4: \"approval\",\n",
    "            5: \"caring\",\n",
    "            6: \"confusion\",\n",
    "            7: \"curiosity\",\n",
    "            8: \"desire\",\n",
    "            9: \"disappointment\",\n",
    "            10: \"disapproval\",\n",
    "            11: \"disgust\",\n",
    "            12: \"embarrassment\",\n",
    "            13: \"excitement\",\n",
    "            14: \"fear\",\n",
    "            15: \"gratitude\",\n",
    "            16: \"grief\",\n",
    "            17: \"joy\",\n",
    "            18: \"love\",\n",
    "            19: \"nervousness\",\n",
    "            20: \"optimism\",\n",
    "            21: \"pride\",\n",
    "            22: \"realization\",\n",
    "            23: \"relief\",\n",
    "            24: \"remorse\",\n",
    "            25: \"sadness\",\n",
    "            26: \"surprise\",\n",
    "            27: \"neutral\",\n",
    "        },\n",
    "        \"model\": \"cointegrated/rubert-tiny2\",\n",
    "        \"tokenizer\": \"cointegrated/rubert-tiny2\",\n",
    "        \"problem_type\": \"multi_label_classification\",\n",
    "        \"batch_size\": 64,\n",
    "        \"epochs\": 50,\n",
    "        \"lr\": 1e-5,\n",
    "    },\n",
    "    \"name\": \"rubert-tiny2-ru-go-emotions\",\n",
    "}\n",
    "config = full_config[\"config\"]"
   ],
   "cell_type": "code",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "source": [
    "def binarize_labels(labels, num_labels):\n",
    "    return [int(i in labels) for i in range(num_labels)]\n",
    "\n",
    "\n",
    "def label2id(class_labels):\n",
    "    label2id = {label: i for i, label in enumerate(class_labels)}\n",
    "    id2label = {i: label for label, i in label2id.items()}\n",
    "    return label2id, id2label"
   ],
   "cell_type": "code",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "source": [
    "def calculate_aucs(y_true, y_pred, num_labels):\n",
    "    return [roc_auc_score(y_true[:, i], y_pred[:, i]) for i in range(num_labels)]\n",
    "\n",
    "\n",
    "def calculate_f1_score(y_true, y_pred, average, num_labels):\n",
    "    return [f1_score(y_true[:, i], y_pred[:, i] > 0.5, average=average) for i in range(num_labels)]\n",
    "\n",
    "\n",
    "def calculate_metrics(y_true, y_pred, num_labels):\n",
    "    auc_rocs = calculate_aucs(y_true, y_pred, num_labels)\n",
    "\n",
    "    f1_scores_micro = calculate_f1_score(y_true, y_pred, \"micro\", num_labels)\n",
    "\n",
    "    f1_scores_macro = calculate_f1_score(y_true, y_pred, \"macro\", num_labels)\n",
    "\n",
    "    df = pd.DataFrame(\n",
    "        [auc_rocs, f1_scores_micro, f1_scores_macro],\n",
    "        columns=config[\"labels\"].values(),\n",
    "        index=[\"AUC ROC\", \"F1 micro\", \"F1 macro\"],\n",
    "    )\n",
    "    df[\"mean\"] = df.mean(axis=1)\n",
    "    # df[\"mean(emotions)\"] = df.drop(\"no emotion\", axis=1).mean(axis=1)\n",
    "    return df"
   ],
   "cell_type": "code",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "source": [
    "def predict(model, dataloader):\n",
    "    with torch.no_grad():\n",
    "        y_true = []\n",
    "        y_pred = []\n",
    "        for batch in dataloader:\n",
    "            batch = batch.to(model.device)\n",
    "            output = model(**batch)\n",
    "            y_true.append(batch.labels)\n",
    "            y_pred.append(torch.softmax(output.logits, -1))\n",
    "    return torch.cat(y_true).cpu().numpy(), torch.cat(y_pred).cpu().numpy()"
   ],
   "cell_type": "code",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "source": [
    "def train(model, train_dataloader, optimizer, epochs, test_dataloader):\n",
    "    tq = tqdm(range(epochs))\n",
    "\n",
    "    for epoch in tq:\n",
    "        model.train()\n",
    "        for i, batch in enumerate(train_dataloader):\n",
    "            optimizer.zero_grad()\n",
    "            batch = batch.to(model.device)\n",
    "            output = model(**batch)\n",
    "            loss = output.loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # if epoch % 5 == 0:\n",
    "        model.eval()\n",
    "\n",
    "        y_true, y_pred = predict(model, train_dataloader)\n",
    "        train_auc = np.mean(calculate_aucs(y_true, y_pred, config[\"num_labels\"]))\n",
    "\n",
    "        y_true, y_pred = predict(model, test_dataloader)\n",
    "        test_auc = np.mean(calculate_aucs(y_true, y_pred, config[\"num_labels\"]))\n",
    "\n",
    "        tq.set_description(f\"loss: {loss.item():4.4f}, AUC: {test_auc:4.4f}\")\n",
    "        wandb.log({\"train_auc\": train_auc, \"test_auc\": test_auc, \"train_loss\": loss.item()})"
   ],
   "cell_type": "code",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "source": [
    "dataset = load_dataset(config[\"dataset\"])"
   ],
   "cell_type": "code",
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Using custom data configuration seara--ru-go-emotions-010f1c10233a04e9\n",
      "Found cached dataset parquet (/home/seara/.cache/huggingface/datasets/seara___parquet/seara--ru-go-emotions-010f1c10233a04e9/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0edaf31639654f9ea375c74bc3ef8755",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(config[\"tokenizer\"])"
   ],
   "cell_type": "code",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "source": [
    "config[\"label2id\"], config[\"id2label\"] = label2id(config[\"labels\"].values())\n",
    "processed_dataset = dataset.map(lambda x: tokenizer(x[\"text\"], truncation=True), batched=True).map(\n",
    "    lambda x: {\"label\": [float(y) for y in binarize_labels(x[\"labels\"], config[\"num_labels\"])]},\n",
    "    batched=False,\n",
    "    remove_columns=[\"text\", \"labels\", \"id\", \"ru_text\"],\n",
    ")"
   ],
   "cell_type": "code",
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Loading cached processed dataset at /home/seara/.cache/huggingface/datasets/seara___parquet/seara--ru-go-emotions-010f1c10233a04e9/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-6a398f7cc851dfd3.arrow\n",
      "Loading cached processed dataset at /home/seara/.cache/huggingface/datasets/seara___parquet/seara--ru-go-emotions-010f1c10233a04e9/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-f9ddef66c5d9538a.arrow\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "128fa8a8208349fb89048cb295040b6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "210b9b6730194324a55c9aa1dfd3dfe7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/43410 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f48c69c19a8a4609ac3e907567a43a30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5426 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a20afebb28a147c485ebe4715977b7e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5427 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {}
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    config[\"model\"],\n",
    "    num_labels=config[\"num_labels\"],\n",
    "    problem_type=config[\"problem_type\"],\n",
    "    label2id=config[\"label2id\"],\n",
    "    id2label=config[\"id2label\"],\n",
    ")"
   ],
   "cell_type": "code",
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of the model checkpoint at cointegrated/rubert-tiny2 were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at cointegrated/rubert-tiny2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer)\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    processed_dataset[\"train\"],\n",
    "    batch_size=config[\"batch_size\"],\n",
    "    drop_last=False,\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    "    collate_fn=data_collator,\n",
    ")\n",
    "test_dataloader = DataLoader(\n",
    "    processed_dataset[\"test\"],\n",
    "    batch_size=config[\"batch_size\"],\n",
    "    drop_last=False,\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    "    collate_fn=data_collator,\n",
    ")"
   ],
   "cell_type": "code",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "source": [
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=config[\"lr\"])"
   ],
   "cell_type": "code",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "source": [
    "os.environ[\"WANDB_NOTEBOOK_NAME\"] = f\"{os.getcwd()}/{full_config['name']}.ipynb\"\n",
    "wandb.login()\n",
    "wandb.init(**full_config)"
   ],
   "cell_type": "code",
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mseara\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "wandb version 0.14.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/seara/Desktop/Github/vkr/new_era/models/wandb/run-20230410_112418-sxb8yacf</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/seara/VKR/runs/sxb8yacf\" target=\"_blank\">rubert-tiny2-ru-go-emotions</a></strong> to <a href=\"https://wandb.ai/seara/VKR\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/seara/VKR/runs/sxb8yacf?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f7b6936e4c0>"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "source": [
    "model.cuda()\n",
    "train(model, train_dataloader, optimizer, config[\"epochs\"], test_dataloader)"
   ],
   "cell_type": "code",
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7cd2ca2bda64426aa77bda17f0a3608",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "source": [
    "calculate_metrics(*predict(model, test_dataloader), config[\"num_labels\"]).round(4)"
   ],
   "cell_type": "code",
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>no emotion</th>\n",
       "      <th>joy</th>\n",
       "      <th>sadness</th>\n",
       "      <th>surprise</th>\n",
       "      <th>fear</th>\n",
       "      <th>anger</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean(emotions)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AUC ROC</th>\n",
       "      <td>0.9239</td>\n",
       "      <td>0.9550</td>\n",
       "      <td>0.9537</td>\n",
       "      <td>0.9045</td>\n",
       "      <td>0.9016</td>\n",
       "      <td>0.7682</td>\n",
       "      <td>0.9011</td>\n",
       "      <td>0.8973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 micro</th>\n",
       "      <td>0.8608</td>\n",
       "      <td>0.9400</td>\n",
       "      <td>0.9336</td>\n",
       "      <td>0.9485</td>\n",
       "      <td>0.9559</td>\n",
       "      <td>0.9192</td>\n",
       "      <td>0.9263</td>\n",
       "      <td>0.9372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 macro</th>\n",
       "      <td>0.8527</td>\n",
       "      <td>0.9005</td>\n",
       "      <td>0.8975</td>\n",
       "      <td>0.8402</td>\n",
       "      <td>0.8350</td>\n",
       "      <td>0.6768</td>\n",
       "      <td>0.8338</td>\n",
       "      <td>0.8306</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          no emotion     joy  sadness  surprise    fear   anger    mean  \\\n",
       "AUC ROC       0.9239  0.9550   0.9537    0.9045  0.9016  0.7682  0.9011   \n",
       "F1 micro      0.8608  0.9400   0.9336    0.9485  0.9559  0.9192  0.9263   \n",
       "F1 macro      0.8527  0.9005   0.8975    0.8402  0.8350  0.6768  0.8338   \n",
       "\n",
       "          mean(emotions)  \n",
       "AUC ROC           0.8973  \n",
       "F1 micro          0.9372  \n",
       "F1 macro          0.8306  "
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "source": [
    "# notebook_login()"
   ],
   "cell_type": "code",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "source": [
    "model.push_to_hub(full_config[\"name\"])\n",
    "tokenizer.push_to_hub(full_config[\"name\"])"
   ],
   "cell_type": "code",
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/seara/rubert-tiny2-cedr/commit/241abd5e1685e91cee1f1843d99cf16c0a8e285f', commit_message='Upload tokenizer', commit_description='', oid='241abd5e1685e91cee1f1843d99cf16c0a8e285f', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "source": [
    "wandb.finish()"
   ],
   "cell_type": "code",
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>test_auc</td><td>▁▂▂▄▅▅▆▇▇▇▇▇▇▇██████████████████████████</td></tr><tr><td>train_auc</td><td>▁▂▂▃▄▄▅▆▆▆▆▇▇▇▇▇▇▇▇█████████████████████</td></tr><tr><td>train_loss</td><td>█▇▆▆▅▄▅▅▅▄▄▄▃▃▃▂▃▃▃▃▂▂▂▂▂▂▃▂▁▂▂▁▁▂▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>test_auc</td><td>0.90113</td></tr><tr><td>train_auc</td><td>0.99792</td></tr><tr><td>train_loss</td><td>0.02599</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">rubert-tiny2-cedr</strong>: <a href=\"https://wandb.ai/seara/VKR/runs/2k3va9u2\" target=\"_blank\">https://wandb.ai/seara/VKR/runs/2k3va9u2</a><br/>Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230408_165201-2k3va9u2/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {}
    }
   ],
   "execution_count": null
  }
 ]
}
